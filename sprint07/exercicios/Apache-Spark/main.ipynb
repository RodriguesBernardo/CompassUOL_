{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "\n",
    "# Inicializa o SparkContext, e faz a leitura do arquivo\n",
    "sc = SparkContext.getOrCreate()\n",
    "arquivo = sc.textFile(\"/home/jovyan/README.md\")\n",
    "\n",
    "# Divide cada linha do arquivo em palavras usando a função flatMap\n",
    "palavras = arquivo.flatMap(lambda line: line.split(\" \"))\n",
    "\n",
    "# Conta o número total de palavras\n",
    "total_palavras = palavras.count()\n",
    "\n",
    "# Cria pares (palavra, 1) para cada palavra\n",
    "paresPalavras = palavras.map(lambda word: (word, 1))\n",
    "\n",
    "# Reduz, somando as ocorrências de cada palavra\n",
    "contador = paresPalavras.reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "# Imprime o número total de palavras\n",
    "print(f\"O número total de palavras é: {total_palavras}\")\n",
    "print(\"---------------------------------------------\")\n",
    "resultado = contador.collect()\n",
    "\n",
    "# Exibe o resultado\n",
    "for palavra, contagem in resultado:\n",
    "    print(f\"{palavra}: {contagem}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
